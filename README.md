# X-MAS Hackathon
 
*MISIS PRISHVARTOVALSYA team*

Team Members:

1. **Вишневский Марк** - Data Engineer
2. **Москвин Владимир** - Analyst
3. **Рыжичкин Кирилл** - Frontend

Презентация: [тык](https://drive.google.com/)

Демонстрация веб-сервиса: [тык](https://drive.google.com/)

Демонстрация Swagger: [тык](https://drive.google.com/)

## Кейс "Высокоэффективный платежный конвейер"

> Необходимо разработать систему оценки уровня эксперта по резюме. Для подсчёта финальной оценки можно учитывать любые факторы, информация о которых дана в резюме. Для реализации можно использовать как готовые модели с подключением по API, так и дообучать open-source модели или создавать свои.

## Оглавление

...

## Блок-схема решения:

...

## Идея решения:

Основная идея: Мы проводим транзакции через конвейер терминалов, чтобы симулировать обработку операций и подсчитать различные метрики. Каждая транзакция обрабатывается через последовательность терминалов, при этом выбираются только те терминалы, которые могут удовлетворить условиям транзакции, таким как валюта, лимит по сумме и другие параметры.

Процесс предобработки данных:
1. Инициализация терминалов: На нулевом времени инициализируются терминалы, представленные в данных. Для них устанавливается начальное состояние (например, начальная сумма на терминале равна нулю).
2. Обработка событий: Каждая запись в таблице с терминалами и транзакциями представляет собой событие. Записи с терминалами считаются событиями типа "TERMINAL", а транзакции — типа "TRANSACTION".
3. Сортировка событий: Все события сортируются сначала по времени, а затем по типу, чтобы сначала обновить информацию о терминале, а затем провести транзакцию.
4. Обработка данных: На основе отсортированных событий данные обрабатываются в цикле. Если событие типа "TERMINAL", обновляется информация о терминале, если транзакция, то она проводится через конвейер терминалов.

Функции и их назначение:
1. proceed_transaction: Симулирует проведение транзакции через конвейер терминалов. Для каждой транзакции определяется, прошло ли оно успешно и сколько времени на это потребовалось.
2. create_conveyor_naive: Создает конвейер терминалов в случайном порядке. Эта функция используется для демонстрации худшего случая, где терминалы добавляются без учета их параметров.
3. create_conveyor: Создает конвейер терминалов, которые могут обработать транзакцию, учитывая валюту, сумму платежа и лимит терминала.
4. get_ids_from_conveyor: Возвращает список ID терминалов, которые обрабатывают транзакцию, для дальнейшего использования в метке "flow".
5. terminal_random: Симулирует успех транзакции через терминал, учитывая вероятность успеха, заданную параметром `CONVERSION`.
6. calculate_next_line: Симулирует выполнение транзакции с учетом текущей информации о терминалах. Создает конвейер терминалов, проводит транзакцию и сохраняет результат.
7. proceed_dataset: Основная функция для обработки всего набора данных. Она выполняет обработку терминалов и транзакций, генерирует конвейеры, выполняет транзакции и возвращает метрики по всем операциям.
8. money_optimization и time_optimization: Оценка оптимизации по деньгам и времени, с использованием коэффициентов для оптимизации.
9. optimization: Функция оптимизации, которая использует библиотеку Optuna для поиска оптимальных значений коэффициентов, которые минимизируют комиссию и время, при этом максимизируя деньги, прошедшие через терминал.

Ключевые метрики:
- money_passed_in_usd: Сумма, которая прошла через терминал в долларах США.
- time_spent: Время, которое потребовалось для обработки транзакции.
- success: Успешность выполнения транзакции.
- success_rate: Процент успешных транзакций.
- fee_in_usd: Платежи, которые необходимо сделать из-за лимитов по сумме.

Процесс работы:
1. Все события (терминалы и транзакции) обрабатываются по порядку.
2. Для каждой транзакции создается конвейер терминалов, которые могут ее обработать.
3. Для каждого конвейера проводятся транзакции, и собираются метрики по каждой операции.
4. Затем метрики агрегируются для всего набора данных, и на основе этих метрик происходит оптимизация коэффициентов с использованием библиотеки Optuna.

Оптимизация:
Для оптимизации коэффициентов, которые влияют на выбор терминалов в конвейере, используется библиотека Optuna. Она находит такие коэффициенты, которые максимально увеличивают сумму денежных переводов через терминалы при минимальных комиссиях и затраченном времени.

Метрики оптимизации:
- Процесс оптимизации производится по метке money_passed_in_usd, которая максимизируется, а также учитываются комиссии, которые уменьшаются с каждым шагом оптимизации.

## Инструкция по запуску:

### Основной скрипт оптимизации цепочек:

Срипт использует argparse для передачи аргументов через командную строку. Он позволяет выбирать файлы с данными и решать, какой из наборов данных использовать для выполнения оптимизации.

Структура команд:
1. Основной синтаксис:
   ```bash
   python main.py
   ```

3. Аргументы:
   - `--providers`: Путь к CSV файлу с данными поставщиков (по умолчанию 'data\providers_1.csv').
   - `--payments`: Путь к CSV файлу с данными о платежах (по умолчанию 'data\payments_1.csv').
   - `--ex_rates`: Путь к CSV файлу с данными о валютных курсах (по умолчанию 'data\ex_rates.csv').
   - `--dataset_1`: Флаг для использования первого набора данных (если установлен, используются предрасчитанные веса для первого набора).
   - `--dataset_2`: Флаг для использования второго набора данных (если установлен, используются предрасчитанные веса для второго набора).

Пример запуска с использованием параметров:
1. Запуск с параметрами по умолчанию:
   ```bash
   python main.py
   ```
   В этом случае будут использованы файлы по умолчанию ('data\providers_1.csv', 'data\payments_1.csv', 'data\ex_rates.csv') и байесовская оптимизация будет запущена заново.

3. Запуск с указанием путей к файлам:
   ```bash
   python main.py --providers 'path\to\your\providers.csv' --payments 'path\to\your\payments.csv' --ex_rates 'path\to\your\ex_rates.csv'
   ```
   В этом случае будут использованы указанные вами пути к файлам данных и байесовская оптимизация также будет запущена с нуля.

5. Запуск с выбором первого набора данных:
   ```bash
   python main.py --dataset_1
   ```
   Здесь будут использоваться предрасчитанные веса для первого набора данных, чтобы не тратить время на повторную оптимизацию.

7. Запуск с выбором второго набора данных:
   ```bash
   python main.py --dataset_2
   ```
   Здесь будут использоваться предрасчитанные веса для второго набора данных, чтобы не тратить время на повторную оптимизацию.

### Фронтенд:

```bash
docker build -t xmas-hack-transactions .
docker run -d -p 8501:8501 xmas-hack-transactions
```

## Наши преимущества:

...

## Структура репозитория

...
